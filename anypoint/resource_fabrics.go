package anypoint

import (
	"context"
	"io"

	"github.com/hashicorp/terraform-plugin-sdk/v2/diag"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/schema"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/validation"
	rtf "github.com/mulesoft-anypoint/anypoint-client-go/rtf"
)

func resourceFabrics() *schema.Resource {
	return &schema.Resource{
		CreateContext: resourceFabricsCreate,
		ReadContext:   resourceFabricsRead,
		UpdateContext: resourceFabricsUpdate,
		DeleteContext: resourceFabricsDelete,
		Description: `
		Creates a ` + "`" + `Runtime Fabrics` + "`" + ` instance.
		`,
		Schema: map[string]*schema.Schema{
			"id": {
				Type:        schema.TypeString,
				Computed:    true,
				Description: "The unique id of this fabrics generated by the anypoint platform.",
			},
			"org_id": {
				Type:        schema.TypeString,
				Required:    true,
				ForceNew:    true,
				Description: "The organization id where the fabrics is defined.",
			},
			"name": {
				Type:        schema.TypeString,
				Required:    true,
				ForceNew:    true,
				Description: "The name of the fabrics",
			},
			"region": {
				Type:     schema.TypeString,
				Required: true,
				ForceNew: true,
				Description: `
				The region where fabrics instance is hosted. Refer to the official documentation for the list of available regions.
				The list of regions is available [here](https://docs.mulesoft.com/cloudhub-2/ch2-architecture#regions-and-dns-records).
				Examples: us-east-1 / us-east-2
				`,
			},
			"vendor": {
				Type:     schema.TypeString,
				Required: true,
				ForceNew: true,
				Description: `
					The vendor name of the kubernetes instance hosting fabrics. The following values are supported:
						* eks: AWS Elastic Kubernetes Service
						* aks: Azure Kubernetes Service
						* gke: Google Kubernetes Service
						* ack: Alibaba Kubernetes Service
						* openshift: Openshift
						* rancher: Rancher
				`,
				ValidateDiagFunc: validation.ToDiagFunc(
					validation.StringInSlice(
						[]string{"eks", "aks", "gke", "ack", "openshift", "rancher"},
						false,
					),
				),
			},
			"vendor_metadata": {
				Type:        schema.TypeMap,
				Computed:    true,
				Description: "The vendor metadata",
			},
			"version": {
				Type:        schema.TypeString,
				Computed:    true,
				Description: "The version of fabrics.",
			},
			"status": {
				Type:        schema.TypeString,
				Computed:    true,
				Description: "The status of the farbics instance.",
			},
			"desired_version": {
				Type:        schema.TypeString,
				Computed:    true,
				Description: "The desired version of fabrics.",
			},
			"available_upgrade_version": {
				Type:        schema.TypeString,
				Computed:    true,
				Description: "The available upgrade version of fabrics.",
			},
			"created_at": {
				Type:        schema.TypeInt,
				Computed:    true,
				Description: "The creation date of the fabrics instance",
			},
			"upgrade": {
				Type:        schema.TypeList,
				Optional:    true,
				Description: "The status of the fabrics. Only available when instance is created and not activated yet. This cannot be set by user, any value the user puts is ignored.",
				Elem:        FabricsUpgradeDefinition,
			},
			"nodes": {
				Type:        schema.TypeList,
				Computed:    true,
				Elem:        NodeDefinition,
				Description: "The list of fabrics nodes.",
			},
			"activation_data": {
				Type:        schema.TypeString,
				Computed:    true,
				Description: "The activation data to use during installation of fabrics on the kubernetes cluster. Only available when instance is created and not activated yet.",
			},
			"seconds_since_heartbeat": {
				Type:        schema.TypeInt,
				Computed:    true,
				Description: "The number of seconds since last heartbeat.",
			},
			"kubernetes_version": {
				Type:        schema.TypeString,
				Computed:    true,
				Description: "The kubernetes version of the cluster.",
			},
			"namespace": {
				Type:        schema.TypeString,
				Computed:    true,
				Description: "The namespace where runtime fabrics is installed.",
			},
			"license_expiry_date": {
				Type:        schema.TypeInt,
				Computed:    true,
				Description: "The expiry date of the license (timestamp).",
			},
			"is_managed": {
				Type:        schema.TypeBool,
				Computed:    true,
				Description: "Whether this cluster is managed.",
			},
			"is_helm_managed": {
				Type:        schema.TypeBool,
				Computed:    true,
				Description: "Whether this cluster is managed by helmet.",
			},
			"app_scoped_log_forwarding": {
				Type:        schema.TypeBool,
				Computed:    true,
				Description: "Whether app scoped log forwarding is active.",
			},
			"cluster_configuration_level": {
				Type:        schema.TypeString,
				Computed:    true,
				Description: "The configuration level of the cluster (production or development).",
			},
			"features": {
				Type:        schema.TypeList,
				Computed:    true,
				Description: "The features of this cluster.",
				Elem:        FabricsFeaturesDefinition,
			},
			"ingress": {
				Type:        schema.TypeList,
				Computed:    true,
				Description: "The ingress configurations of this cluster.",
				Elem:        FabricsIngressDomainsDefinition,
			},
		},
		Importer: &schema.ResourceImporter{
			StateContext: schema.ImportStatePassthroughContext,
		},
	}
}

func resourceFabricsCreate(ctx context.Context, d *schema.ResourceData, m interface{}) diag.Diagnostics {
	var diags diag.Diagnostics
	pco := m.(ProviderConfOutput)
	orgid := d.Get("org_id").(string)
	name := d.Get("name").(string)
	authctx := getFabricsAuthCtx(ctx, &pco)
	body := prepareFabricsPostBody(d)
	//prepare request
	res, httpr, err := pco.rtfclient.DefaultApi.PostFabrics(authctx, orgid).FabricsPostBody(*body).Execute()
	if err != nil {
		var details string
		if httpr != nil && httpr.StatusCode >= 400 {
			defer httpr.Body.Close()
			b, _ := io.ReadAll(httpr.Body)
			details = string(b)
		} else {
			details = err.Error()
		}
		diags = append(diags, diag.Diagnostic{
			Severity: diag.Error,
			Summary:  "Unable to create fabrics " + name,
			Detail:   details,
		})
		return diags
	}
	defer httpr.Body.Close()

	id := res.GetId()
	d.SetId(id)
	return resourceFabricsRead(ctx, d, m)
}

func resourceFabricsRead(ctx context.Context, d *schema.ResourceData, m interface{}) diag.Diagnostics {
	var diags diag.Diagnostics
	pco := m.(ProviderConfOutput)
	fabricsid := d.Id()
	orgid := d.Get("org_id").(string)
	authctx := getFabricsAuthCtx(ctx, &pco)
	if isComposedResourceId(fabricsid) {
		orgid, fabricsid = decomposeFabricsId(d)
	}
	//perform request
	res, httpr, err := pco.rtfclient.DefaultApi.GetFabrics(authctx, orgid, fabricsid).Execute()
	if err != nil {
		var details string
		if httpr != nil && httpr.StatusCode >= 400 {
			defer httpr.Body.Close()
			b, _ := io.ReadAll(httpr.Body)
			details = string(b)
		} else {
			details = err.Error()
		}
		diags := append(diags, diag.Diagnostic{
			Severity: diag.Error,
			Summary:  "Unable to read fabrics " + fabricsid,
			Detail:   details,
		})
		return diags
	}
	defer httpr.Body.Close()
	//process data
	data := flattenFabricsData(res)
	//save in data source schema
	if err := setFabricsResourceData(d, data); err != nil {
		diags := append(diags, diag.Diagnostic{
			Severity: diag.Error,
			Summary:  "Unable to set fabrics " + fabricsid,
			Detail:   err.Error(),
		})
		return diags
	}
	d.SetId(fabricsid)
	d.Set("org_id", orgid)
	return diags
}

func resourceFabricsUpdate(ctx context.Context, d *schema.ResourceData, m interface{}) diag.Diagnostics {
	return resourceFabricsRead(ctx, d, m)
}

func resourceFabricsDelete(ctx context.Context, d *schema.ResourceData, m interface{}) diag.Diagnostics {
	var diags diag.Diagnostics
	pco := m.(ProviderConfOutput)
	fabricsid := d.Id()
	orgid := d.Get("org_id").(string)
	authctx := getFabricsAuthCtx(ctx, &pco)
	//perform request
	httpr, err := pco.rtfclient.DefaultApi.DeleteFabrics(authctx, orgid, fabricsid).Execute()
	if err != nil {
		var details string
		if httpr != nil && httpr.StatusCode >= 400 {
			defer httpr.Body.Close()
			b, _ := io.ReadAll(httpr.Body)
			details = string(b)
		} else {
			details = err.Error()
		}
		diags := append(diags, diag.Diagnostic{
			Severity: diag.Error,
			Summary:  "Unable to delete fabrics " + fabricsid,
			Detail:   details,
		})
		return diags
	}
	defer httpr.Body.Close()
	// d.SetId("") is automatically called assuming delete returns no errors, but
	// it is added here for explicitness.
	d.SetId("")

	return diags
}

func prepareFabricsPostBody(d *schema.ResourceData) *rtf.FabricsPostBody {
	body := rtf.NewFabricsPostBody()
	body.SetName(d.Get("name").(string))
	body.SetVendor(d.Get("vendor").(string))
	body.SetRegion(d.Get("region").(string))
	return body
}

func decomposeFabricsId(d *schema.ResourceData) (string, string) {
	s := DecomposeResourceId(d.Id())
	return s[0], s[1]
}

/*
 * Returns authentication context (includes authorization header)
 */
func getFabricsAuthCtx(ctx context.Context, pco *ProviderConfOutput) context.Context {
	tmp := context.WithValue(ctx, rtf.ContextAccessToken, pco.access_token)
	return context.WithValue(tmp, rtf.ContextServerIndex, pco.server_index)
}
